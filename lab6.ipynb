{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SnrPep/Mos/blob/main/lab6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "train_test_split AutoTokenizer AutoModelForSequenceClassification TrainingArguments Trainer DataCollatorWithPadding evaluate numpy os"
      ],
      "metadata": {
        "id": "1yjavJQiyJkf"
      },
      "id": "1yjavJQiyJkf"
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m ipykernel install --user --name=colab-env\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FdJzLypw0Kp4",
        "outputId": "ae4c0f4b-0818-44a5-b473-598a5a6228c3"
      },
      "id": "FdJzLypw0Kp4",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installed kernelspec colab-env in C:\\Users\\Konstantin\\AppData\\Roaming\\jupyter\\kernels\\colab-env\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "109dT7I0kXtF",
        "outputId": "3e1db6d8-0c2b-4e81-aead-675cd68cbc92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "D:\\dfsd\\colab-env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "from transformers import DataCollatorWithPadding\n",
        "import evaluate\n",
        "import numpy as np\n",
        "import os\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\""
      ],
      "id": "109dT7I0kXtF"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "S1DC9jNtkXtF"
      },
      "outputs": [],
      "source": [
        "url = \"https://raw.githubusercontent.com/dD2405/Twitter_Sentiment_Analysis/master/train.csv\"\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "df = df[df['label'].isin([0, 1])].reset_index(drop=True)\n",
        "df = df.head(1500)\n",
        "\n",
        "\n",
        "# Деление на train/val/test\n",
        "train_df, temp_df = train_test_split(df, test_size=0.2, stratify=df['label'], random_state=42)\n",
        "val_df, test_df = train_test_split(temp_df, test_size=0.5, stratify=temp_df['label'], random_state=42)\n",
        "\n",
        "train_dataset = Dataset.from_pandas(train_df)\n",
        "val_dataset = Dataset.from_pandas(val_df)\n",
        "test_dataset = Dataset.from_pandas(test_df)"
      ],
      "id": "S1DC9jNtkXtF"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VkVB7LZ1kXtF",
        "outputId": "8d0bd1d7-7539-4090-f247-352a5e28bc10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Map: 100%|███████████████████████████████████████████████████████████████| 1200/1200 [00:00<00:00, 17076.74 examples/s]\n",
            "Map: 100%|██████████████████████████████████████████████████████████████████| 150/150 [00:00<00:00, 8550.03 examples/s]\n",
            "Map: 100%|█████████████████████████████████████████████████████████████████| 150/150 [00:00<00:00, 11828.05 examples/s]\n"
          ]
        }
      ],
      "source": [
        "# Токенизация\n",
        "checkpoint = \"distilbert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "\n",
        "def tokenize(example):\n",
        "    return tokenizer(example[\"tweet\"], truncation=True)\n",
        "\n",
        "train_dataset = train_dataset.map(tokenize, batched=True)\n",
        "val_dataset = val_dataset.map(tokenize, batched=True)\n",
        "test_dataset = test_dataset.map(tokenize, batched=True)"
      ],
      "id": "VkVB7LZ1kXtF"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4yP-7DokXtG",
        "outputId": "7407bb30-6fc6-4ee2-80a5-6c5cf52009ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
          ]
        }
      ],
      "source": [
        "# Модель и аргументы обучения\n",
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"results\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        ")\n",
        "\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ],
      "id": "K4yP-7DokXtG"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "8toIqRJGkXtG"
      },
      "outputs": [],
      "source": [
        "# Метрики\n",
        "accuracy = evaluate.load(\"accuracy\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    return accuracy.compute(predictions=predictions, references=labels)"
      ],
      "id": "8toIqRJGkXtG"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "id": "73732VXskXtG",
        "outputId": "23faaef7-1ba9-4e3f-cd64-697c5e442073"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\Temp\\ipykernel_9908\\3629407656.py:2: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "D:\\dfsd\\colab-env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='225' max='225' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [225/225 06:28, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=225, training_loss=0.18434410942925347, metrics={'train_runtime': 391.8909, 'train_samples_per_second': 9.186, 'train_steps_per_second': 0.574, 'total_flos': 36420255417984.0, 'train_loss': 0.18434410942925347, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# Обучение\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "trainer.train()"
      ],
      "id": "73732VXskXtG"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "A2_6MIPakXtG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "c550250b-9513-4f0e-f531-94238e63b270"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "D:\\dfsd\\colab-env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.9333333333333333\n"
          ]
        }
      ],
      "source": [
        "# Тестирование\n",
        "preds = trainer.predict(test_dataset)\n",
        "print(\"Test Accuracy:\", preds.metrics['test_accuracy'])"
      ],
      "id": "A2_6MIPakXtG"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6rWhzpgkXtG"
      },
      "source": [
        "### Вывод\n",
        "- Модель DistilBERT успешно классифицировала твиты на два класса.\n",
        "- Использование токенизатора `distilbert-base-uncased` позволило эффективно обработать тексты.\n",
        "- Достигнута высокая точность на валидационной и тестовой выборках.\n",
        "- Hugging Face Transformers значительно упрощают весь ML pipeline для NLP задач."
      ],
      "id": "e6rWhzpgkXtG"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "colab-env",
      "name": "colab-env"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}